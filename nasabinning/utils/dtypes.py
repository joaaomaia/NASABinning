# nasabinning/utils/dtypes.py
from __future__ import annotations
import warnings, pandas as pd
from typing import List, Optional, Tuple


def search_dtypes(
    df: pd.DataFrame, 
    target_col: str = 'target', 
    limite_categorico: int = 50, 
    force_categorical: Optional[List[str]] = None, 
    verbose: bool = True, 
    remove_ids: bool = False,
    id_patterns: Optional[List[str]] = None
) -> Tuple[List[str], List[str]]:
    """
    Identifica e classifica colunas num√©ricas e categ√≥ricas em um DataFrame.

    Funcionalidades:
    - Valida entradas e trata erros de forma robusta
    - For√ßa colunas espec√≠ficas como categ√≥ricas
    - Classifica automaticamente por tipo de dados e cardinalidade
    - Remove colunas de ID opcionalmente
    - Suporte a padr√µes customizados para identifica√ß√£o de IDs

    Par√¢metros:
    -----------
    df : pd.DataFrame
        DataFrame de entrada para an√°lise
    target_col : str, default 'target'
        Nome da coluna target a ser exclu√≠da da an√°lise
    limite_categorico : int, default 50
        M√°ximo de valores √∫nicos para considerar coluna object como categ√≥rica
    force_categorical : List[str], optional
        Lista de colunas que devem ser for√ßadas como categ√≥ricas
    verbose : bool, default True
        Se True, imprime detalhes das decis√µes tomadas
    remove_ids : bool, default False
        Se True, remove colunas identificadas como IDs
    id_patterns : List[str], optional
        Padr√µes para identificar colunas de ID (ex: ['_id', 'id_', 'codigo'])

    Retorna:
    --------
    Tuple[List[str], List[str]]
        Tupla contendo (colunas_numericas, colunas_categoricas)

    Raises:
    -------
    ValueError
        Se o DataFrame estiver vazio ou se target_col n√£o existir
    TypeError
        Se os tipos dos par√¢metros estiverem incorretos
    """
    
    # Valida√ß√µes iniciais
    if not isinstance(df, pd.DataFrame):
        raise TypeError("O par√¢metro 'df' deve ser um pandas DataFrame")
    
    if df.empty:
        raise ValueError("O DataFrame n√£o pode estar vazio")
    
    if not isinstance(target_col, str):
        raise TypeError("O par√¢metro 'target_col' deve ser uma string")
    
    if not isinstance(limite_categorico, int) or limite_categorico <= 0:
        raise ValueError("O par√¢metro 'limite_categorico' deve ser um inteiro positivo")
    
    # Verifica se target_col existe no DataFrame
    if target_col not in df.columns:
        available_cols = ", ".join(df.columns.tolist()[:10])  # Mostra apenas primeiras 10
        suffix = "..." if len(df.columns) > 10 else ""
        raise ValueError(
            f"Coluna target '{target_col}' n√£o encontrada no DataFrame. "
            f"Colunas dispon√≠veis: {available_cols}{suffix}"
        )
    
    # Inicializa√ß√£o de vari√°veis
    num_cols = []
    cat_cols = []
    ignored_cols = []
    
    # Tratamento de par√¢metros opcionais
    force_categorical = force_categorical or []
    id_patterns = id_patterns or ['client_id', '_id', 'id_', 'codigo', 'key']
    
    # Valida√ß√£o do force_categorical
    if not isinstance(force_categorical, list):
        raise TypeError("O par√¢metro 'force_categorical' deve ser uma lista de strings")
    
    # Verifica se colunas em force_categorical existem
    missing_forced = [col for col in force_categorical if col not in df.columns]
    if missing_forced:
        warnings.warn(
            f"Colunas em force_categorical n√£o encontradas: {missing_forced}",
            UserWarning
        )
        force_categorical = [col for col in force_categorical if col in df.columns]
    
    # Cria DataFrame sem a coluna target
    try:
        df_work = df.drop(columns=[target_col], errors='raise')
    except KeyError as e:
        raise ValueError(f"Erro ao remover coluna target: {e}")
    
    if verbose:
        print(f"Analisando {len(df_work.columns)} colunas (excluindo target '{target_col}')...")
        print("-" * 60)
    
    # An√°lise das colunas
    for col in df_work.columns:
        try:
            # Obter informa√ß√µes b√°sicas da coluna
            tipo = df_work[col].dtype
            non_null_count = df_work[col].count()
            total_count = len(df_work)
            missing_pct = ((total_count - non_null_count) / total_count) * 100
            
            # For√ßa colunas explicitamente marcadas como categ√≥ricas
            if col in force_categorical:
                cat_cols.append(col)
                if verbose:
                    print(f"‚úì '{col}' -> CATEG√ìRICA (for√ßada)")
                continue
            
            # Verifica se √© coluna com muitos valores missing
            if missing_pct > 90:
                ignored_cols.append(col)
                if verbose:
                    print(f"‚ö† '{col}' -> IGNORADA ({missing_pct:.1f}% valores ausentes)")
                continue
            
            # Classifica√ß√£o por tipo de dados
            if pd.api.types.is_numeric_dtype(tipo):
                # Verifica se √© uma coluna ID num√©rica
                if remove_ids and _is_id_column(col, df_work[col], id_patterns):
                    ignored_cols.append(col)
                    if verbose:
                        print(f"üóë '{col}' -> REMOVIDA (identificada como ID)")
                else:
                    num_cols.append(col)
                    if verbose:
                        unique_count = df_work[col].nunique(dropna=True)
                        print(f"üìä '{col}' -> NUM√âRICA ({unique_count} valores √∫nicos)")
            
            elif tipo == 'object' or pd.api.types.is_string_dtype(tipo):
                # Remove IDs textuais se solicitado
                if remove_ids and _is_id_column(col, df_work[col], id_patterns):
                    ignored_cols.append(col)
                    if verbose:
                        print(f"üóë '{col}' -> REMOVIDA (identificada como ID)")
                    continue
                
                unique_count = df_work[col].nunique(dropna=True)
                
                if unique_count <= limite_categorico:
                    cat_cols.append(col)
                    if verbose:
                        print(f"üè∑ '{col}' -> CATEG√ìRICA ({unique_count} categorias)")
                else:
                    ignored_cols.append(col)
                    if verbose:
                        print(f"‚ö† '{col}' -> IGNORADA (muitas categorias: {unique_count})")
            
            elif pd.api.types.is_bool_dtype(tipo):
                cat_cols.append(col)
                if verbose:
                    print(f"‚òë '{col}' -> CATEG√ìRICA (booleana)")
            
            elif pd.api.types.is_datetime64_any_dtype(tipo):
                ignored_cols.append(col)
                if verbose:
                    print(f"üìÖ '{col}' -> IGNORADA (datetime)")
            
            else:
                ignored_cols.append(col)
                if verbose:
                    print(f"‚ùì '{col}' -> IGNORADA (tipo n√£o suportado: {tipo})")
        
        except Exception as e:
            ignored_cols.append(col)
            if verbose:
                print(f"‚ùå '{col}' -> ERRO ao processar: {str(e)}")
            warnings.warn(f"Erro ao processar coluna '{col}': {str(e)}", UserWarning)
    
    # Remo√ß√£o adicional de IDs se solicitado
    if remove_ids:
        num_cols, cat_cols = _remove_id_columns(num_cols, cat_cols, id_patterns, verbose)
    
    # Relat√≥rio final
    if verbose:
        print("\n" + "="*60)
        print("RESUMO DA CLASSIFICA√á√ÉO:")
        print("="*60)
        
        print(f"\nüìä VARI√ÅVEIS NUM√âRICAS ({len(num_cols)}):")
        if num_cols:
            for col in sorted(num_cols):
                print(f"   ‚Ä¢ {col}")
        else:
            print("   (nenhuma encontrada)")
        
        print(f"\nüè∑ VARI√ÅVEIS CATEG√ìRICAS ({len(cat_cols)}):")
        if cat_cols:
            for col in sorted(cat_cols):
                print(f"   ‚Ä¢ {col}")
        else:
            print("   (nenhuma encontrada)")
        
        if ignored_cols:
            print(f"\n‚ö† COLUNAS IGNORADAS ({len(ignored_cols)}):")
            for col in sorted(ignored_cols):
                print(f"   ‚Ä¢ {col}")
        
        print(f"\nüìà ESTAT√çSTICAS:")
        print(f"   ‚Ä¢ Total de colunas analisadas: {len(df_work.columns)}")
        print(f"   ‚Ä¢ Colunas num√©ricas: {len(num_cols)}")
        print(f"   ‚Ä¢ Colunas categ√≥ricas: {len(cat_cols)}")
        print(f"   ‚Ä¢ Colunas ignoradas: {len(ignored_cols)}")
        print(f"   ‚Ä¢ Taxa de utiliza√ß√£o: {((len(num_cols) + len(cat_cols)) / len(df_work.columns) * 100):.1f}%")
    
    return num_cols, cat_cols


def _is_id_column(col_name: str, col_data: pd.Series, id_patterns: List[str]) -> bool:
    """
    Verifica se uma coluna √© provavelmente um ID baseado no nome e caracter√≠sticas.
    
    Par√¢metros:
    -----------
    col_name : str
        Nome da coluna
    col_data : pd.Series
        Dados da coluna
    id_patterns : List[str]
        Padr√µes para identificar IDs
    
    Retorna:
    --------
    bool
        True se a coluna for identificada como ID
    """
    col_lower = col_name.lower()
    
    # Verifica padr√µes no nome
    name_match = any(pattern.lower() in col_lower for pattern in id_patterns)
    
    # Verifica caracter√≠sticas dos dados
    unique_ratio = col_data.nunique() / len(col_data) if len(col_data) > 0 else 0
    high_uniqueness = unique_ratio > 0.95  # Mais de 95% de valores √∫nicos
    
    return name_match or high_uniqueness


def _remove_id_columns(num_cols: List[str], cat_cols: List[str], 
                      id_patterns: List[str], verbose: bool) -> Tuple[List[str], List[str]]:
    """
    Remove colunas identificadas como IDs das listas de colunas num√©ricas e categ√≥ricas.
    
    Par√¢metros:
    -----------
    num_cols : List[str]
        Lista de colunas num√©ricas
    cat_cols : List[str]
        Lista de colunas categ√≥ricas
    id_patterns : List[str]
        Padr√µes para identificar IDs
    verbose : bool
        Se True, imprime remo√ß√µes
    
    Retorna:
    --------
    Tuple[List[str], List[str]]
        Tupla com listas atualizadas (num_cols, cat_cols)
    """
    original_num = len(num_cols)
    original_cat = len(cat_cols)
    
    # Remove IDs das colunas num√©ricas
    num_cols_filtered = []
    for col in num_cols:
        if not any(pattern.lower() in col.lower() for pattern in id_patterns):
            num_cols_filtered.append(col)
        elif verbose:
            print(f"üóë Removendo '{col}' das num√©ricas (padr√£o ID detectado)")
    
    # Remove IDs das colunas categ√≥ricas
    cat_cols_filtered = []
    for col in cat_cols:
        if not any(pattern.lower() in col.lower() for pattern in id_patterns):
            cat_cols_filtered.append(col)
        elif verbose:
            print(f"üóë Removendo '{col}' das categ√≥ricas (padr√£o ID detectado)")
    
    removed_count = (original_num + original_cat) - (len(num_cols_filtered) + len(cat_cols_filtered))
    if verbose and removed_count > 0:
        print(f"üìã Total de colunas ID removidas: {removed_count}")
    
    return num_cols_filtered, cat_cols_filtered